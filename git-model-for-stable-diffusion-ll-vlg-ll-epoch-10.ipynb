{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --no-index --no-deps /kaggle/input/lavis-pretrained/salesforce-lavis/transformers* \n!pip install --no-index --no-deps /kaggle/input/lavis-pretrained/salesforce-lavis/hugging*\nimport torch","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:51:50.832394Z","iopub.execute_input":"2023-06-22T11:51:50.832784Z","iopub.status.idle":"2023-06-22T11:51:55.414247Z","shell.execute_reply.started":"2023-06-22T11:51:50.832754Z","shell.execute_reply":"2023-06-22T11:51:55.413038Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/lavis-pretrained/salesforce-lavis/transformers-4.26.1-py3-none-any.whl\ntransformers is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mProcessing /kaggle/input/lavis-pretrained/salesforce-lavis/huggingface_hub-0.12.0-py3-none-any.whl\nhuggingface-hub is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"TRAINING = False","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:46:09.729034Z","iopub.execute_input":"2023-06-22T12:46:09.729833Z","iopub.status.idle":"2023-06-22T12:46:09.735394Z","shell.execute_reply.started":"2023-06-22T12:46:09.729767Z","shell.execute_reply":"2023-06-22T12:46:09.733584Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 10\nSEED = 2023\nT_MAX = 500\nMIN_LR = 1e-6\nN_ACCUMULATE = 1\nWEIGHT_DECAY = 1e-6\nLEARNING_RATE = 1e-4\nVALID_BATCH_SIZE = 8\nTRAIN_BATCH_SIZE = 4\nSCHEDULER = 'CosineAnnealingLR'\nDATASET = 'poloclub/diffusiondb'\nMODEL_NAME = \"/kaggle/input/image-caption-models/git-base\"\nDEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:52:02.533500Z","iopub.execute_input":"2023-06-22T11:52:02.533889Z","iopub.status.idle":"2023-06-22T11:52:02.540360Z","shell.execute_reply.started":"2023-06-22T11:52:02.533857Z","shell.execute_reply":"2023-06-22T11:52:02.539047Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 8\nEMBEDDING_LENGTH = 384\nTRAINED_MODEL_PATH = '/kaggle/input/git-base-trained-epoch10/git_base_trained.pt'\nOFFLINE_BACKBONE_PATH = \"/kaggle/input/image-caption-models/git-base\"\nSENTENCE_TRANSFORMERS_MODEL = '/kaggle/input/sentence-transformers-222/all-MiniLM-L6-v2'","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:46:03.589053Z","iopub.execute_input":"2023-06-22T12:46:03.589450Z","iopub.status.idle":"2023-06-22T12:46:03.595229Z","shell.execute_reply.started":"2023-06-22T12:46:03.589419Z","shell.execute_reply":"2023-06-22T12:46:03.594075Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport copy\nimport time\nimport torch\nimport joblib\nimport random\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\nfrom tqdm import tqdm\nimport torch.optim as optim\nfrom datasets import load_dataset\nfrom collections import defaultdict\nfrom torch.optim import lr_scheduler\nfrom transformers import AutoProcessor, AdamW\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import GitVisionModel\nimport warnings; warnings.filterwarnings(\"ignore\")\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nos.environ['TOKENIZERS_PARALLELISM'] = \"False\"","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:52:03.440318Z","iopub.execute_input":"2023-06-22T11:52:03.440686Z","iopub.status.idle":"2023-06-22T11:52:03.448563Z","shell.execute_reply.started":"2023-06-22T11:52:03.440655Z","shell.execute_reply":"2023-06-22T11:52:03.447441Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed=42):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)    \n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False    \n    os.environ['PYTHONHASHSEED'] = str(seed)    \nset_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:52:03.912422Z","iopub.execute_input":"2023-06-22T11:52:03.912770Z","iopub.status.idle":"2023-06-22T11:52:03.920112Z","shell.execute_reply.started":"2023-06-22T11:52:03.912742Z","shell.execute_reply":"2023-06-22T11:52:03.919039Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"class ImageCaptioningDataset(Dataset):\n    def __init__(self, dataset, processor):\n        self.dataset = dataset\n        self.processor = processor\n    def __len__(self): return len(self.dataset)\n    def __getitem__(self, idx):\n        item = self.dataset[idx]\n        return {k:v.squeeze() for k,v in self.processor(images=item[\"image\"], text=item[\"prompt\"], padding=\"max_length\", return_tensors=\"pt\").items()}","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:52:04.352719Z","iopub.execute_input":"2023-06-22T11:52:04.353390Z","iopub.status.idle":"2023-06-22T11:52:04.359747Z","shell.execute_reply.started":"2023-06-22T11:52:04.353351Z","shell.execute_reply":"2023-06-22T11:52:04.358781Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    model.train()    \n    dataset_size = 0\n    running_loss = 0.0    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:\n        input_ids = data['input_ids'].to(device)\n        pixel_values = data['pixel_values'].to(device)        \n        batch_size = input_ids.size(0)\n        outputs = model(input_ids=input_ids, pixel_values=pixel_values, labels=input_ids)                \n        loss = outputs.loss\n        loss = loss / N_ACCUMULATE\n        loss.backward()    \n        if (step + 1) % N_ACCUMULATE == 0:\n            optimizer.step()            \n            optimizer.zero_grad()\n            if scheduler is not None: scheduler.step()                \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size        \n        epoch_loss = running_loss / dataset_size        \n        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss, LR=optimizer.param_groups[0]['lr'])\n    gc.collect()    \n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:52:04.782184Z","iopub.execute_input":"2023-06-22T11:52:04.782551Z","iopub.status.idle":"2023-06-22T11:52:04.792809Z","shell.execute_reply.started":"2023-06-22T11:52:04.782520Z","shell.execute_reply":"2023-06-22T11:52:04.791655Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef valid_one_epoch(model, dataloader, device, epoch):\n    model.eval()    \n    dataset_size = 0\n    running_loss = 0.0    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:        \n        input_ids = data['input_ids'].to(device)\n        pixel_values = data['pixel_values'].to(device)        \n        batch_size = input_ids.size(0)\n        outputs = model(input_ids=input_ids, pixel_values=pixel_values, labels=input_ids)                \n        loss = outputs.loss        \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size        \n        epoch_loss = running_loss / dataset_size        \n        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss, LR=optimizer.param_groups[0]['lr'])    \n    gc.collect()    \n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:52:05.242353Z","iopub.execute_input":"2023-06-22T11:52:05.242713Z","iopub.status.idle":"2023-06-22T11:52:05.250915Z","shell.execute_reply.started":"2023-06-22T11:52:05.242682Z","shell.execute_reply":"2023-06-22T11:52:05.249693Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def run_training(model, optimizer, scheduler, num_epochs):\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_epoch_loss = np.inf    \n    for epoch in range(1, num_epochs + 1): \n        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, dataloader=train_loader, device=DEVICE, epoch=epoch)\n        val_epoch_loss = valid_one_epoch(model, valid_loader, device=DEVICE, epoch=epoch)\n        if val_epoch_loss <= best_epoch_loss:\n            print(f\"Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n            best_epoch_loss = val_epoch_loss            \n            best_model_wts = copy.deepcopy(model.state_dict())\n            torch.save(model.state_dict(), f\"BestLoss.bin\")\n    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n    model.load_state_dict(best_model_wts)    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:52:05.680151Z","iopub.execute_input":"2023-06-22T11:52:05.681066Z","iopub.status.idle":"2023-06-22T11:52:05.689548Z","shell.execute_reply.started":"2023-06-22T11:52:05.681023Z","shell.execute_reply":"2023-06-22T11:52:05.688377Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"# Using 2m_first_1k instead of 2m_fisrt_5k due to less computational power :(((","metadata":{}},{"cell_type":"code","source":"if TRAINING:\n    processor = AutoProcessor.from_pretrained(MODEL_NAME)\n    dataset = load_dataset(DATASET, '2m_first_1k')\n    dataset = dataset['train']\n    dataset = dataset.filter(lambda example: example[\"step\"] == 50)\n    dataset = dataset.train_test_split(test_size=0.1)\n    train_dataset = ImageCaptioningDataset(dataset['train'], processor)\n    valid_dataset = ImageCaptioningDataset(dataset['test'], processor)\n    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=TRAIN_BATCH_SIZE)\n    valid_loader = DataLoader(valid_dataset, shuffle=False, batch_size=VALID_BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:52:07.942246Z","iopub.execute_input":"2023-06-22T11:52:07.942616Z","iopub.status.idle":"2023-06-22T11:52:42.973213Z","shell.execute_reply.started":"2023-06-22T11:52:07.942586Z","shell.execute_reply":"2023-06-22T11:52:42.972263Z"},"trusted":true},"execution_count":44,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5cb586be90d4f40866623588e7bb575"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a77a98136886451d9f58355ff583faed"}},"metadata":{}}]},{"cell_type":"markdown","source":"# **Loading model** (GiT)","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(\"/kaggle/input/image-caption-models/git-base\")","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:52:42.975447Z","iopub.execute_input":"2023-06-22T11:52:42.975853Z","iopub.status.idle":"2023-06-22T11:52:44.958840Z","shell.execute_reply.started":"2023-06-22T11:52:42.975816Z","shell.execute_reply":"2023-06-22T11:52:44.957868Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"**Training the model**","metadata":{}},{"cell_type":"code","source":"if TRAINING:\n    model.to(DEVICE)\n    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n    scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=T_MAX, eta_min=MIN_LR)\n    model = run_training(model, optimizer, scheduler, num_epochs=EPOCHS)\n    del train_loader, valid_loader\n    _ = gc.collect()\n    torch.save(model.state_dict(), 'git_base_trained.pt')","metadata":{"execution":{"iopub.status.busy":"2023-06-22T11:52:44.960305Z","iopub.execute_input":"2023-06-22T11:52:44.960748Z","iopub.status.idle":"2023-06-22T12:22:31.059500Z","shell.execute_reply.started":"2023-06-22T11:52:44.960714Z","shell.execute_reply":"2023-06-22T12:22:31.058368Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"100%|██████████| 225/225 [02:46<00:00,  1.35it/s, Epoch=1, LR=5.82e-5, Train_Loss=1.49]\n100%|██████████| 13/13 [00:06<00:00,  1.86it/s, Epoch=1, LR=5.82e-5, Valid_Loss=0.233]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss Improved (inf ---> 0.23304848074913026)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 225/225 [02:49<00:00,  1.33it/s, Epoch=2, LR=3.42e-6, Train_Loss=0.198]\n100%|██████████| 13/13 [00:06<00:00,  1.87it/s, Epoch=2, LR=3.42e-6, Valid_Loss=0.189]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss Improved (0.23304848074913026 ---> 0.18868886590003967)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 225/225 [02:50<00:00,  1.32it/s, Epoch=3, LR=2.8e-5, Train_Loss=0.168] \n100%|██████████| 13/13 [00:07<00:00,  1.81it/s, Epoch=3, LR=2.8e-5, Valid_Loss=0.182]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss Improved (0.18868886590003967 ---> 0.18191296756267547)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 225/225 [02:49<00:00,  1.33it/s, Epoch=4, LR=9.05e-5, Train_Loss=0.157]\n100%|██████████| 13/13 [00:06<00:00,  1.86it/s, Epoch=4, LR=9.05e-5, Valid_Loss=0.16] \n","output_type":"stream"},{"name":"stdout","text":"Validation Loss Improved (0.18191296756267547 ---> 0.16041039705276489)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 225/225 [02:49<00:00,  1.32it/s, Epoch=5, LR=8.55e-5, Train_Loss=0.118]\n100%|██████████| 13/13 [00:06<00:00,  1.87it/s, Epoch=5, LR=8.55e-5, Valid_Loss=0.136]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss Improved (0.16041039705276489 ---> 0.1356866678595543)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 225/225 [02:49<00:00,  1.32it/s, Epoch=6, LR=2.14e-5, Train_Loss=0.0728]\n100%|██████████| 13/13 [00:07<00:00,  1.79it/s, Epoch=6, LR=2.14e-5, Valid_Loss=0.118]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss Improved (0.1356866678595543 ---> 0.11836093425750732)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 225/225 [02:49<00:00,  1.33it/s, Epoch=7, LR=6.4e-6, Train_Loss=0.0493] \n100%|██████████| 13/13 [00:07<00:00,  1.81it/s, Epoch=7, LR=6.4e-6, Valid_Loss=0.116]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss Improved (0.11836093425750732 ---> 0.11626948237419128)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 225/225 [02:49<00:00,  1.33it/s, Epoch=8, LR=6.58e-5, Train_Loss=0.0497]\n100%|██████████| 13/13 [00:06<00:00,  1.86it/s, Epoch=8, LR=6.58e-5, Valid_Loss=0.12] \n100%|██████████| 225/225 [02:49<00:00,  1.33it/s, Epoch=9, LR=9.94e-5, Train_Loss=0.0559]\n100%|██████████| 13/13 [00:06<00:00,  1.87it/s, Epoch=9, LR=9.94e-5, Valid_Loss=0.124]\n100%|██████████| 225/225 [02:49<00:00,  1.32it/s, Epoch=10, LR=5.05e-5, Train_Loss=0.0462]\n100%|██████████| 13/13 [00:06<00:00,  1.88it/s, Epoch=10, LR=5.05e-5, Valid_Loss=0.114]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss Improved (0.11626948237419128 ---> 0.1144895851612091)\nBest Loss: 0.1145\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Loading Trained Model**","metadata":{}},{"cell_type":"code","source":"# model.load_state_dict(torch.load('/kaggle/working/git_base_trained.pt'))\n# model.to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T21:25:51.445064Z","iopub.execute_input":"2023-06-21T21:25:51.445466Z","iopub.status.idle":"2023-06-21T21:25:51.829452Z","shell.execute_reply.started":"2023-06-21T21:25:51.445435Z","shell.execute_reply":"2023-06-21T21:25:51.828370Z"},"trusted":true},"execution_count":110,"outputs":[{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"GitForCausalLM(\n  (git): GitModel(\n    (embeddings): GitEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(1024, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (image_encoder): GitVisionModel(\n      (vision_model): GitVisionTransformer(\n        (embeddings): GitVisionEmbeddings(\n          (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)\n          (position_embedding): Embedding(197, 768)\n        )\n        (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (encoder): GitVisionEncoder(\n          (layers): ModuleList(\n            (0-11): 12 x GitVisionEncoderLayer(\n              (self_attn): GitVisionAttention(\n                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n              )\n              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (mlp): GitVisionMLP(\n                (activation_fn): QuickGELUActivation()\n                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n              )\n              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            )\n          )\n        )\n        (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (encoder): GitEncoder(\n      (layer): ModuleList(\n        (0-5): 6 x GitLayer(\n          (attention): GitAttention(\n            (self): GitSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): GitSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): GitIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): GitOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (visual_projection): GitProjection(\n      (visual_projection): Sequential(\n        (0): Linear(in_features=768, out_features=768, bias=True)\n        (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n  (output): Linear(in_features=768, out_features=30522, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"import sys; sys.path.append('../input/sentence-transformers-222/sentence-transformers')\nimport os\nimport sys\nimport cv2\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom sentence_transformers import SentenceTransformer, models\nfrom transformers import AutoProcessor, GitVisionModel,GitVisionModel","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:46:21.768741Z","iopub.execute_input":"2023-06-22T12:46:21.769461Z","iopub.status.idle":"2023-06-22T12:46:21.775506Z","shell.execute_reply.started":"2023-06-22T12:46:21.769427Z","shell.execute_reply":"2023-06-22T12:46:21.774526Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# from transformers import AutoModelForCausalLM\n\n# model = AutoModelForCausalLM.from_pretrained(\"/kaggle/input/image-caption-models/git-base\")","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:46:24.488941Z","iopub.execute_input":"2023-06-22T12:46:24.489328Z","iopub.status.idle":"2023-06-22T12:46:24.493761Z","shell.execute_reply.started":"2023-06-22T12:46:24.489298Z","shell.execute_reply":"2023-06-22T12:46:24.492863Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"if not TRAINING:\n    processor = AutoProcessor.from_pretrained(OFFLINE_BACKBONE_PATH)\n    model.from_pretrained(OFFLINE_BACKBONE_PATH)\n    model.load_state_dict(torch.load(TRAINED_MODEL_PATH))\n    model.to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:46:38.727747Z","iopub.execute_input":"2023-06-22T12:46:38.728283Z","iopub.status.idle":"2023-06-22T12:46:41.240641Z","shell.execute_reply.started":"2023-06-22T12:46:38.728246Z","shell.execute_reply":"2023-06-22T12:46:41.239648Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"import glob","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:46:41.242692Z","iopub.execute_input":"2023-06-22T12:46:41.243156Z","iopub.status.idle":"2023-06-22T12:46:41.247742Z","shell.execute_reply.started":"2023-06-22T12:46:41.243121Z","shell.execute_reply":"2023-06-22T12:46:41.246584Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"if not TRAINING:\n    data_directory = \"/kaggle/input/stable-diffusion-image-to-prompts/images\"\n    data_pattern = os.path.sep.join([data_directory,\"*.png\"])\n    image_path_list = list(glob.glob(data_pattern))\n    raw_image = Image.open(image_path_list[5]).convert(\"RGB\")\n    pixel_values = processor(images=[raw_image], return_tensors=\"pt\").pixel_values.to(DEVICE)\n    out = model.generate(pixel_values=pixel_values, max_length=20, min_length=5)\n    prompts = processor.batch_decode(out, skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:46:46.287081Z","iopub.execute_input":"2023-06-22T12:46:46.287467Z","iopub.status.idle":"2023-06-22T12:46:47.203820Z","shell.execute_reply.started":"2023-06-22T12:46:46.287435Z","shell.execute_reply":"2023-06-22T12:46:47.202777Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"prompts","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:46:47.205740Z","iopub.execute_input":"2023-06-22T12:46:47.206130Z","iopub.status.idle":"2023-06-22T12:46:47.213095Z","shell.execute_reply.started":"2023-06-22T12:46:47.206097Z","shell.execute_reply":"2023-06-22T12:46:47.211877Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"['a gauguinesque, russet oil painting on canvas shows four red apples and two']"},"metadata":{}}]},{"cell_type":"code","source":"comp_path = '/kaggle/input/stable-diffusion-image-to-prompts'","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:46:50.631229Z","iopub.execute_input":"2023-06-22T12:46:50.631670Z","iopub.status.idle":"2023-06-22T12:46:50.638801Z","shell.execute_reply.started":"2023-06-22T12:46:50.631640Z","shell.execute_reply":"2023-06-22T12:46:50.637838Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"if not TRAINING:\n    st_model = SentenceTransformer(SENTENCE_TRANSFORMERS_MODEL)\n    images = os.listdir(comp_path +\"/images\")\n    image_ids = [i.split('.')[0] for i in images]\n    eIds = list(range(EMBEDDING_LENGTH))\n    imgId_eId = [\n        '_'.join(map(str, i)) for i in zip(\n            np.repeat(image_ids, EMBEDDING_LENGTH),\n            np.tile(range(EMBEDDING_LENGTH), len(image_ids)))]","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:46:51.734254Z","iopub.execute_input":"2023-06-22T12:46:51.734709Z","iopub.status.idle":"2023-06-22T12:46:53.372076Z","shell.execute_reply.started":"2023-06-22T12:46:51.734673Z","shell.execute_reply":"2023-06-22T12:46:53.371121Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"def make_batches(image_ids, batch_size=3):\n    num_images = len(image_ids)\n    num_batches = (num_images + batch_size - 1) // batch_size  # Ceiling division\n\n    batches = []\n    for i in range(num_batches):\n        start_index = i * batch_size\n        end_index = min(start_index + batch_size, num_images)\n        batch = image_ids[start_index:end_index]\n        batches.append(batch)\n\n    return batches\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:46:56.579725Z","iopub.execute_input":"2023-06-22T12:46:56.580423Z","iopub.status.idle":"2023-06-22T12:46:56.586652Z","shell.execute_reply.started":"2023-06-22T12:46:56.580390Z","shell.execute_reply":"2023-06-22T12:46:56.585507Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"if not TRAINING:\n    submissions = []\n    ids_ = []\n    prompts_=[]\n    for batch in make_batches(images):\n        images_batch = []\n        for i, image in enumerate(batch): \n            img = Image.open(comp_path+\"/images/\"+image).convert(\"RGB\")\n            pixel_values = processor(images = img, return_tensors=\"pt\").pixel_values.to(DEVICE)\n            out = model.generate(pixel_values=pixel_values, max_length=20, min_length=5)\n            prompts = processor.batch_decode(out, skip_special_tokens=True)\n            prompts_.extend(prompts)\n            embeddings = st_model.encode(prompts_).flatten()\n            submissions.extend(embeddings)\n            EMBEDDING_LENGTH = len(embeddings)\n            ## \n            image_ids = image\n            Ids = list(range(EMBEDDING_LENGTH))\n            imgId_eId = [\n                '_'.join(map(str, i)) for i in zip(\n                    np.repeat(image_ids, EMBEDDING_LENGTH),\n                    np.tile(range(EMBEDDING_LENGTH), len(image_ids)))]\n    \n            ids_.extend(imgId_eId)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:46:59.215878Z","iopub.execute_input":"2023-06-22T12:46:59.216240Z","iopub.status.idle":"2023-06-22T12:47:05.218565Z","shell.execute_reply.started":"2023-06-22T12:46:59.216210Z","shell.execute_reply":"2023-06-22T12:47:05.217615Z"},"trusted":true},"execution_count":61,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ba3299db3454c2d8b3b986a2d9ed4ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7aafe4caf4da47bfac8b5d274e31932a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aeffc9e4eab547b892e69d93c720e60a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd8fcd84efa74db19a44765514fb8a4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2eb9d98ead704ca58ea0a334a7f6fcdb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f28221ff14045088ef509f8e47030d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21ec99ec1d2c442badc375bcfd770105"}},"metadata":{}}]},{"cell_type":"code","source":"len(submissions)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:47:08.896753Z","iopub.execute_input":"2023-06-22T12:47:08.897159Z","iopub.status.idle":"2023-06-22T12:47:08.904681Z","shell.execute_reply.started":"2023-06-22T12:47:08.897126Z","shell.execute_reply":"2023-06-22T12:47:08.903771Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"10752"},"metadata":{}}]},{"cell_type":"code","source":"if not TRAINING:\n    submission = pd.DataFrame({\"imgId_eId\":ids_, \"val\": submissions})\n    submission.to_csv(\"submission.csv\", index=False)\n    submission.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:47:10.339227Z","iopub.execute_input":"2023-06-22T12:47:10.339617Z","iopub.status.idle":"2023-06-22T12:47:10.394444Z","shell.execute_reply.started":"2023-06-22T12:47:10.339585Z","shell.execute_reply":"2023-06-22T12:47:10.393407Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"len(submissions)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:47:12.009548Z","iopub.execute_input":"2023-06-22T12:47:12.009942Z","iopub.status.idle":"2023-06-22T12:47:12.016933Z","shell.execute_reply.started":"2023-06-22T12:47:12.009909Z","shell.execute_reply":"2023-06-22T12:47:12.015813Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"10752"},"metadata":{}}]},{"cell_type":"code","source":"len(imgId_eId)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T12:47:13.398841Z","iopub.execute_input":"2023-06-22T12:47:13.399722Z","iopub.status.idle":"2023-06-22T12:47:13.406278Z","shell.execute_reply.started":"2023-06-22T12:47:13.399675Z","shell.execute_reply":"2023-06-22T12:47:13.405154Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"2688"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}