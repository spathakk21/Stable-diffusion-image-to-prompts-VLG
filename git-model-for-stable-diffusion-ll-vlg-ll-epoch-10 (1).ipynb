{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --no-index --no-deps /kaggle/input/lavis-pretrained/salesforce-lavis/transformers* \n!pip install --no-index --no-deps /kaggle/input/lavis-pretrained/salesforce-lavis/hugging*\nimport torch","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:35:59.580941Z","iopub.execute_input":"2023-06-22T14:35:59.581312Z","iopub.status.idle":"2023-06-22T14:36:16.288005Z","shell.execute_reply.started":"2023-06-22T14:35:59.581281Z","shell.execute_reply":"2023-06-22T14:36:16.286950Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/lavis-pretrained/salesforce-lavis/transformers-4.26.1-py3-none-any.whl\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.30.1\n    Uninstalling transformers-4.30.1:\n      Successfully uninstalled transformers-4.30.1\nSuccessfully installed transformers-4.26.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mProcessing /kaggle/input/lavis-pretrained/salesforce-lavis/huggingface_hub-0.12.0-py3-none-any.whl\nInstalling collected packages: huggingface-hub\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.15.1\n    Uninstalling huggingface-hub-0.15.1:\n      Successfully uninstalled huggingface-hub-0.15.1\nSuccessfully installed huggingface-hub-0.12.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"TRAINING = False","metadata":{"execution":{"iopub.status.busy":"2023-06-22T15:29:18.792938Z","iopub.execute_input":"2023-06-22T15:29:18.793664Z","iopub.status.idle":"2023-06-22T15:29:18.798405Z","shell.execute_reply.started":"2023-06-22T15:29:18.793631Z","shell.execute_reply":"2023-06-22T15:29:18.797345Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 10\nSEED = 2023\nT_MAX = 500\nMIN_LR = 1e-6\nN_ACCUMULATE = 1\nWEIGHT_DECAY = 1e-6\nLEARNING_RATE = 1e-4\nVALID_BATCH_SIZE = 8\nTRAIN_BATCH_SIZE = 4\nSCHEDULER = 'CosineAnnealingLR'\nDATASET = 'poloclub/diffusiondb'\nMODEL_NAME = \"/kaggle/input/image-caption-models/git-base\"\nDEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:36:16.303343Z","iopub.execute_input":"2023-06-22T14:36:16.304169Z","iopub.status.idle":"2023-06-22T14:36:16.465373Z","shell.execute_reply.started":"2023-06-22T14:36:16.304118Z","shell.execute_reply":"2023-06-22T14:36:16.464195Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 8\nEMBEDDING_LENGTH = 384\nTRAINED_MODEL_PATH = '/kaggle/input/git-base-trained-epoch10/git_base_trained.pt'\nOFFLINE_BACKBONE_PATH = \"/kaggle/input/image-caption-models/git-base\"\nSENTENCE_TRANSFORMERS_MODEL = '/kaggle/input/sentence-transformers-222/all-MiniLM-L6-v2'","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:36:16.468434Z","iopub.execute_input":"2023-06-22T14:36:16.468866Z","iopub.status.idle":"2023-06-22T14:36:16.476019Z","shell.execute_reply.started":"2023-06-22T14:36:16.468830Z","shell.execute_reply":"2023-06-22T14:36:16.475086Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport copy\nimport time\nimport torch\nimport joblib\nimport random\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\nfrom tqdm import tqdm\nimport torch.optim as optim\nfrom datasets import load_dataset\nfrom collections import defaultdict\nfrom torch.optim import lr_scheduler\nfrom transformers import AutoProcessor, AdamW\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import GitVisionModel\nimport warnings; warnings.filterwarnings(\"ignore\")\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nos.environ['TOKENIZERS_PARALLELISM'] = \"False\"","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:36:16.477884Z","iopub.execute_input":"2023-06-22T14:36:16.478257Z","iopub.status.idle":"2023-06-22T14:36:28.608526Z","shell.execute_reply.started":"2023-06-22T14:36:16.478227Z","shell.execute_reply":"2023-06-22T14:36:28.607609Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"def set_seed(seed=42):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)    \n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False    \n    os.environ['PYTHONHASHSEED'] = str(seed)    \nset_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:36:28.609810Z","iopub.execute_input":"2023-06-22T14:36:28.610166Z","iopub.status.idle":"2023-06-22T14:36:28.623213Z","shell.execute_reply.started":"2023-06-22T14:36:28.610105Z","shell.execute_reply":"2023-06-22T14:36:28.622204Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class ImageCaptioningDataset(Dataset):\n    def __init__(self, dataset, processor):\n        self.dataset = dataset\n        self.processor = processor\n    def __len__(self): return len(self.dataset)\n    def __getitem__(self, idx):\n        item = self.dataset[idx]\n        return {k:v.squeeze() for k,v in self.processor(images=item[\"image\"], text=item[\"prompt\"], padding=\"max_length\", return_tensors=\"pt\").items()}","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:36:28.624910Z","iopub.execute_input":"2023-06-22T14:36:28.626082Z","iopub.status.idle":"2023-06-22T14:36:28.635263Z","shell.execute_reply.started":"2023-06-22T14:36:28.626047Z","shell.execute_reply":"2023-06-22T14:36:28.634314Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    model.train()    \n    dataset_size = 0\n    running_loss = 0.0    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:\n        input_ids = data['input_ids'].to(device)\n        pixel_values = data['pixel_values'].to(device)        \n        batch_size = input_ids.size(0)\n        outputs = model(input_ids=input_ids, pixel_values=pixel_values, labels=input_ids)                \n        loss = outputs.loss\n        loss = loss / N_ACCUMULATE\n        loss.backward()    \n        if (step + 1) % N_ACCUMULATE == 0:\n            optimizer.step()            \n            optimizer.zero_grad()\n            if scheduler is not None: scheduler.step()                \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size        \n        epoch_loss = running_loss / dataset_size        \n        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss, LR=optimizer.param_groups[0]['lr'])\n    gc.collect()    \n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:36:28.638456Z","iopub.execute_input":"2023-06-22T14:36:28.638752Z","iopub.status.idle":"2023-06-22T14:36:28.649609Z","shell.execute_reply.started":"2023-06-22T14:36:28.638728Z","shell.execute_reply":"2023-06-22T14:36:28.648726Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef valid_one_epoch(model, dataloader, device, epoch):\n    model.eval()    \n    dataset_size = 0\n    running_loss = 0.0    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:        \n        input_ids = data['input_ids'].to(device)\n        pixel_values = data['pixel_values'].to(device)        \n        batch_size = input_ids.size(0)\n        outputs = model(input_ids=input_ids, pixel_values=pixel_values, labels=input_ids)                \n        loss = outputs.loss        \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size        \n        epoch_loss = running_loss / dataset_size        \n        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss, LR=optimizer.param_groups[0]['lr'])    \n    gc.collect()    \n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:36:28.650946Z","iopub.execute_input":"2023-06-22T14:36:28.651566Z","iopub.status.idle":"2023-06-22T14:36:28.664439Z","shell.execute_reply.started":"2023-06-22T14:36:28.651532Z","shell.execute_reply":"2023-06-22T14:36:28.663332Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def run_training(model, optimizer, scheduler, num_epochs):\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_epoch_loss = np.inf    \n    for epoch in range(1, num_epochs + 1): \n        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, dataloader=train_loader, device=DEVICE, epoch=epoch)\n        val_epoch_loss = valid_one_epoch(model, valid_loader, device=DEVICE, epoch=epoch)\n        if val_epoch_loss <= best_epoch_loss:\n            print(f\"Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n            best_epoch_loss = val_epoch_loss            \n            best_model_wts = copy.deepcopy(model.state_dict())\n            torch.save(model.state_dict(), f\"BestLoss.bin\")\n    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n    model.load_state_dict(best_model_wts)    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:36:28.668596Z","iopub.execute_input":"2023-06-22T14:36:28.669041Z","iopub.status.idle":"2023-06-22T14:36:28.678160Z","shell.execute_reply.started":"2023-06-22T14:36:28.669017Z","shell.execute_reply":"2023-06-22T14:36:28.677332Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Using 2m_first_1k instead of 2m_fisrt_5k due to less computational power :(((","metadata":{}},{"cell_type":"code","source":"if TRAINING:\n    processor = AutoProcessor.from_pretrained(MODEL_NAME)\n    dataset = load_dataset(DATASET, '2m_first_1k')\n    dataset = dataset['train']\n    dataset = dataset.filter(lambda example: example[\"step\"] == 50)\n    dataset = dataset.train_test_split(test_size=0.1)\n    train_dataset = ImageCaptioningDataset(dataset['train'], processor)\n    valid_dataset = ImageCaptioningDataset(dataset['test'], processor)\n    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=TRAIN_BATCH_SIZE)\n    valid_loader = DataLoader(valid_dataset, shuffle=False, batch_size=VALID_BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:36:28.679868Z","iopub.execute_input":"2023-06-22T14:36:28.680475Z","iopub.status.idle":"2023-06-22T14:37:12.892177Z","shell.execute_reply.started":"2023-06-22T14:36:28.680443Z","shell.execute_reply":"2023-06-22T14:37:12.891258Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c01fef3b64404f23b180deb50bf6561c"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset diffusion_db/2m_first_1k to /root/.cache/huggingface/datasets/poloclub___diffusion_db/2m_first_1k/0.9.1/b3bc1e64570dc7149af62c4bac49ecfbce16b683dd4fee083292fae1afa95f7c...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/581M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f6a84785aeb4efeb50b53896d0a9035"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/195M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58246a1c7d9142d7813878131118b749"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset diffusion_db downloaded and prepared to /root/.cache/huggingface/datasets/poloclub___diffusion_db/2m_first_1k/0.9.1/b3bc1e64570dc7149af62c4bac49ecfbce16b683dd4fee083292fae1afa95f7c. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f393a309946941eba4339f41f8aa2836"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90a667119af24f968ab53826a84d2543"}},"metadata":{}}]},{"cell_type":"markdown","source":"# **Loading model** (GiT)","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(\"/kaggle/input/image-caption-models/git-base\")","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:37:12.893509Z","iopub.execute_input":"2023-06-22T14:37:12.893951Z","iopub.status.idle":"2023-06-22T14:37:23.471392Z","shell.execute_reply.started":"2023-06-22T14:37:12.893918Z","shell.execute_reply":"2023-06-22T14:37:23.470302Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**Training the model**","metadata":{}},{"cell_type":"code","source":"if TRAINING:\n    model.to(DEVICE)\n    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n    scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=T_MAX, eta_min=MIN_LR)\n    model = run_training(model, optimizer, scheduler, num_epochs=EPOCHS)\n    del train_loader, valid_loader\n    _ = gc.collect()\n    torch.save(model.state_dict(), 'git_base_trained.pt')","metadata":{"execution":{"iopub.status.busy":"2023-06-22T14:37:23.472928Z","iopub.execute_input":"2023-06-22T14:37:23.474413Z","iopub.status.idle":"2023-06-22T15:07:38.421563Z","shell.execute_reply.started":"2023-06-22T14:37:23.474379Z","shell.execute_reply":"2023-06-22T15:07:38.420546Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"100%|██████████| 225/225 [02:54<00:00,  1.29it/s, Epoch=1, LR=5.82e-5, Train_Loss=1.48]\n100%|██████████| 13/13 [00:07<00:00,  1.86it/s, Epoch=1, LR=5.82e-5, Valid_Loss=0.243]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss Improved (inf ---> 0.2433512318134308)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 225/225 [02:52<00:00,  1.31it/s, Epoch=2, LR=3.42e-6, Train_Loss=0.192]\n100%|██████████| 13/13 [00:07<00:00,  1.85it/s, Epoch=2, LR=3.42e-6, Valid_Loss=0.203]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss Improved (0.2433512318134308 ---> 0.20305414080619813)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 225/225 [02:51<00:00,  1.31it/s, Epoch=3, LR=2.8e-5, Train_Loss=0.162] \n100%|██████████| 13/13 [00:07<00:00,  1.84it/s, Epoch=3, LR=2.8e-5, Valid_Loss=0.195]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss Improved (0.20305414080619813 ---> 0.19522417724132538)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 225/225 [02:51<00:00,  1.31it/s, Epoch=4, LR=9.05e-5, Train_Loss=0.153]\n100%|██████████| 13/13 [00:06<00:00,  1.87it/s, Epoch=4, LR=9.05e-5, Valid_Loss=0.175]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss Improved (0.19522417724132538 ---> 0.17517206728458404)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 225/225 [02:51<00:00,  1.31it/s, Epoch=5, LR=8.55e-5, Train_Loss=0.118]\n100%|██████████| 13/13 [00:07<00:00,  1.80it/s, Epoch=5, LR=8.55e-5, Valid_Loss=0.151]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss Improved (0.17517206728458404 ---> 0.15130146771669387)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 225/225 [02:51<00:00,  1.31it/s, Epoch=6, LR=2.14e-5, Train_Loss=0.0739]\n100%|██████████| 13/13 [00:06<00:00,  1.86it/s, Epoch=6, LR=2.14e-5, Valid_Loss=0.136]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss Improved (0.15130146771669387 ---> 0.1361661371588707)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 225/225 [02:51<00:00,  1.31it/s, Epoch=7, LR=6.4e-6, Train_Loss=0.0507] \n100%|██████████| 13/13 [00:06<00:00,  1.88it/s, Epoch=7, LR=6.4e-6, Valid_Loss=0.134]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss Improved (0.1361661371588707 ---> 0.13421210169792175)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 225/225 [02:51<00:00,  1.31it/s, Epoch=8, LR=6.58e-5, Train_Loss=0.0504]\n100%|██████████| 13/13 [00:07<00:00,  1.76it/s, Epoch=8, LR=6.58e-5, Valid_Loss=0.137]\n100%|██████████| 225/225 [02:51<00:00,  1.31it/s, Epoch=9, LR=9.94e-5, Train_Loss=0.0564]\n100%|██████████| 13/13 [00:06<00:00,  1.87it/s, Epoch=9, LR=9.94e-5, Valid_Loss=0.14] \n100%|██████████| 225/225 [02:51<00:00,  1.31it/s, Epoch=10, LR=5.05e-5, Train_Loss=0.0458]\n100%|██████████| 13/13 [00:06<00:00,  1.88it/s, Epoch=10, LR=5.05e-5, Valid_Loss=0.134]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss Improved (0.13421210169792175 ---> 0.13411744803190231)\nBest Loss: 0.1341\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Inferencing part by my trained model **--> '/kaggle/input/git-base-trained-epoch10'","metadata":{}},{"cell_type":"markdown","source":"# **Set 'TRAINING = False' and run the cell below**","metadata":{}},{"cell_type":"code","source":"import sys; sys.path.append('../input/sentence-transformers-222/sentence-transformers')\nimport os\nimport sys\nimport cv2\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom sentence_transformers import SentenceTransformer, models\nfrom transformers import AutoProcessor, GitVisionModel,GitVisionModel","metadata":{"execution":{"iopub.status.busy":"2023-06-22T15:29:05.493249Z","iopub.execute_input":"2023-06-22T15:29:05.494279Z","iopub.status.idle":"2023-06-22T15:29:07.140501Z","shell.execute_reply.started":"2023-06-22T15:29:05.494244Z","shell.execute_reply":"2023-06-22T15:29:07.139347Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# from transformers import AutoModelForCausalLM\n\n# model = AutoModelForCausalLM.from_pretrained(\"/kaggle/input/git-base-trained-epoch10/git_base_trained.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-06-22T15:29:09.067873Z","iopub.execute_input":"2023-06-22T15:29:09.068265Z","iopub.status.idle":"2023-06-22T15:29:09.072984Z","shell.execute_reply.started":"2023-06-22T15:29:09.068232Z","shell.execute_reply":"2023-06-22T15:29:09.071513Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"if not TRAINING:\n    processor = AutoProcessor.from_pretrained(OFFLINE_BACKBONE_PATH)\n    model.from_pretrained(OFFLINE_BACKBONE_PATH)\n    model.load_state_dict(torch.load(TRAINED_MODEL_PATH))\n    model.to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T15:29:09.387828Z","iopub.execute_input":"2023-06-22T15:29:09.388217Z","iopub.status.idle":"2023-06-22T15:29:09.394511Z","shell.execute_reply.started":"2023-06-22T15:29:09.388187Z","shell.execute_reply":"2023-06-22T15:29:09.393549Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import glob","metadata":{"execution":{"iopub.status.busy":"2023-06-22T15:29:28.312962Z","iopub.execute_input":"2023-06-22T15:29:28.313335Z","iopub.status.idle":"2023-06-22T15:29:28.318325Z","shell.execute_reply.started":"2023-06-22T15:29:28.313306Z","shell.execute_reply":"2023-06-22T15:29:28.317210Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"if not TRAINING:\n    data_directory = \"/kaggle/input/stable-diffusion-image-to-prompts/images\"\n    data_pattern = os.path.sep.join([data_directory,\"*.png\"])\n    image_path_list = list(glob.glob(data_pattern))\n    raw_image = Image.open(image_path_list[5]).convert(\"RGB\")\n    pixel_values = processor(images=[raw_image], return_tensors=\"pt\").pixel_values.to(DEVICE)\n    out = model.generate(pixel_values=pixel_values, max_length=20, min_length=5)\n    prompts = processor.batch_decode(out, skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T15:29:49.013249Z","iopub.execute_input":"2023-06-22T15:29:49.013650Z","iopub.status.idle":"2023-06-22T15:29:49.940603Z","shell.execute_reply.started":"2023-06-22T15:29:49.013621Z","shell.execute_reply":"2023-06-22T15:29:49.939629Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"prompts","metadata":{"execution":{"iopub.status.busy":"2023-06-22T15:29:51.372908Z","iopub.execute_input":"2023-06-22T15:29:51.373293Z","iopub.status.idle":"2023-06-22T15:29:51.379110Z","shell.execute_reply.started":"2023-06-22T15:29:51.373264Z","shell.execute_reply":"2023-06-22T15:29:51.378215Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"['a portrait of girl alchemist in blue dress, witch hat, magic potions, fantasy,']"},"metadata":{}}]},{"cell_type":"code","source":"comp_path = '/kaggle/input/stable-diffusion-image-to-prompts'","metadata":{"execution":{"iopub.status.busy":"2023-06-22T15:32:17.268396Z","iopub.execute_input":"2023-06-22T15:32:17.268805Z","iopub.status.idle":"2023-06-22T15:32:17.276854Z","shell.execute_reply.started":"2023-06-22T15:32:17.268774Z","shell.execute_reply":"2023-06-22T15:32:17.275952Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"if not TRAINING:\n    st_model = SentenceTransformer(SENTENCE_TRANSFORMERS_MODEL)\n    images = os.listdir(comp_path +\"/images\")\n    image_ids = [i.split('.')[0] for i in images]\n    eIds = list(range(EMBEDDING_LENGTH))\n    imgId_eId = [\n        '_'.join(map(str, i)) for i in zip(\n            np.repeat(image_ids, EMBEDDING_LENGTH),\n            np.tile(range(EMBEDDING_LENGTH), len(image_ids)))]","metadata":{"execution":{"iopub.status.busy":"2023-06-22T15:32:21.528053Z","iopub.execute_input":"2023-06-22T15:32:21.529081Z","iopub.status.idle":"2023-06-22T15:32:23.235370Z","shell.execute_reply.started":"2023-06-22T15:32:21.529039Z","shell.execute_reply":"2023-06-22T15:32:23.234289Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def make_batches(image_ids, batch_size=3):\n    num_images = len(image_ids)\n    num_batches = (num_images + batch_size - 1) // batch_size  # Ceiling division\n\n    batches = []\n    for i in range(num_batches):\n        start_index = i * batch_size\n        end_index = min(start_index + batch_size, num_images)\n        batch = image_ids[start_index:end_index]\n        batches.append(batch)\n\n    return batches\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T15:32:24.368029Z","iopub.execute_input":"2023-06-22T15:32:24.368911Z","iopub.status.idle":"2023-06-22T15:32:24.376157Z","shell.execute_reply.started":"2023-06-22T15:32:24.368868Z","shell.execute_reply":"2023-06-22T15:32:24.374547Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"if not TRAINING:\n    submissions = []\n    ids_ = []\n    prompts_=[]\n    for batch in make_batches(images):\n        images_batch = []\n        for i, image in enumerate(batch): \n            img = Image.open(comp_path+\"/images/\"+image).convert(\"RGB\")\n            pixel_values = processor(images = img, return_tensors=\"pt\").pixel_values.to(DEVICE)\n            out = model.generate(pixel_values=pixel_values, max_length=20, min_length=5)\n            prompts = processor.batch_decode(out, skip_special_tokens=True)\n            prompts_.extend(prompts)\n            embeddings = st_model.encode(prompts_).flatten()\n            submissions.extend(embeddings)\n            EMBEDDING_LENGTH = len(embeddings)\n            ## \n            image_ids = image\n            Ids = list(range(EMBEDDING_LENGTH))\n            imgId_eId = [\n                '_'.join(map(str, i)) for i in zip(\n                    np.repeat(image_ids, EMBEDDING_LENGTH),\n                    np.tile(range(EMBEDDING_LENGTH), len(image_ids)))]\n    \n            ids_.extend(imgId_eId)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T15:32:25.198214Z","iopub.execute_input":"2023-06-22T15:32:25.199273Z","iopub.status.idle":"2023-06-22T15:32:31.307658Z","shell.execute_reply.started":"2023-06-22T15:32:25.199239Z","shell.execute_reply":"2023-06-22T15:32:31.306724Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e615f587c4a4485c8be18c47cf260384"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ae6d986515742959df2bca72d1918eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04bfcf47b0ae41ec8df5abf51114a318"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2385e5342912434197370d9d34bff41c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68d2f8efe8ea4a0aabee0a5eab863e74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"287bccc185c74db194fdb6f45736717c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95b7364444c34db8aee62087623969bf"}},"metadata":{}}]},{"cell_type":"code","source":"len(submissions)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T15:32:31.309722Z","iopub.execute_input":"2023-06-22T15:32:31.310088Z","iopub.status.idle":"2023-06-22T15:32:31.321228Z","shell.execute_reply.started":"2023-06-22T15:32:31.310055Z","shell.execute_reply":"2023-06-22T15:32:31.315377Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"10752"},"metadata":{}}]},{"cell_type":"code","source":"if not TRAINING:\n    submission = pd.DataFrame({\"imgId_eId\":ids_, \"val\": submissions})\n    submission.to_csv(\"submission.csv\", index=False)\n    submission.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-22T15:32:31.323039Z","iopub.execute_input":"2023-06-22T15:32:31.323436Z","iopub.status.idle":"2023-06-22T15:32:31.385222Z","shell.execute_reply.started":"2023-06-22T15:32:31.323393Z","shell.execute_reply":"2023-06-22T15:32:31.384200Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"len(submissions)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T15:32:31.387371Z","iopub.execute_input":"2023-06-22T15:32:31.387689Z","iopub.status.idle":"2023-06-22T15:32:31.394869Z","shell.execute_reply.started":"2023-06-22T15:32:31.387661Z","shell.execute_reply":"2023-06-22T15:32:31.393591Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"10752"},"metadata":{}}]},{"cell_type":"code","source":"len(imgId_eId)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T15:32:31.396418Z","iopub.execute_input":"2023-06-22T15:32:31.397537Z","iopub.status.idle":"2023-06-22T15:32:31.405987Z","shell.execute_reply.started":"2023-06-22T15:32:31.397500Z","shell.execute_reply":"2023-06-22T15:32:31.404673Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"2688"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}